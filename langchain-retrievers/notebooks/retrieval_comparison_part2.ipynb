{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Multi-Query Retriever vs Self-Querying Retriever Comparison\n",
        "\n",
        "## Overview\n",
        "\n",
        "This notebook compares two advanced retrieval techniques in LangChain:\n",
        "- **Multi-Query Retriever**: Generates multiple query variations to capture different perspectives\n",
        "- **Self-Querying Retriever**: Uses LLM to construct structured queries with metadata filters\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Setup and Imports\n",
        "\n",
        "Import all necessary libraries for document processing, embeddings, vector stores, and retrievers."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/erfan/.local/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ All imports successful!\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Core LangChain imports\n",
        "\n",
        "from langchain.embeddings import HuggingFaceEmbeddings\n",
        "from langchain.vectorstores import Chroma\n",
        "from langchain.retrievers.multi_query import MultiQueryRetriever\n",
        "from langchain.retrievers.self_query.base import SelfQueryRetriever\n",
        "from langchain.chains.query_constructor.base import AttributeInfo\n",
        "from langchain_core.documents import Document\n",
        "from langchain_community.llms import Ollama\n",
        "\n",
        "import sys\n",
        "import warnings\n",
        "import logging\n",
        "sys.path.append('..')\n",
        "import config\n",
        "from langchain_core.prompts import PromptTemplate\n",
        "from langchain_community.llms import Ollama\n",
        "\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "print(\"‚úÖ All imports successful!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Initialize Embedding Model\n",
        "\n",
        "Set up logging for debugging and initialize the HuggingFace embedding model for document vectorization."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üî§ Initializing embedding model...\n",
            "‚úÖ Embedding model ready!\n"
          ]
        }
      ],
      "source": [
        "\n",
        "logging.basicConfig()\n",
        "logging.getLogger(\"langchain.retrievers.multi_query\").setLevel(logging.INFO)\n",
        "\n",
        "# Initialize embedding model\n",
        "print(\"üî§ Initializing embedding model...\")\n",
        "embeddings = HuggingFaceEmbeddings(\n",
        "    model_name=\"sentence-transformers/all-MiniLM-L6-v2\",\n",
        "    model_kwargs={'device': 'cuda'},\n",
        ")\n",
        "print(\"‚úÖ Embedding model ready!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Initialize Large Language Models\n",
        "\n",
        "Configure the Ollama LLM (Gemma 3:1b) for query generation and processing."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from langchain_openai import ChatOpenAI\n",
        "import os\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "# Load from .env file (never commit .env to git!)\n",
        "load_dotenv()\n",
        "\n",
        "# Validate API key exists\n",
        "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
        "if not api_key:\n",
        "    raise ValueError(\"‚ùå OPENAI_API_KEY not found in environment variables. Please set it in .env file\")\n",
        "\n",
        "llm_self_query = ChatOpenAI(\n",
        "    model=\"gpt-4o-mini\",\n",
        "    temperature=0.0,\n",
        "    max_tokens=512\n",
        ")\n",
        "\n",
        "llm_multi_query = Ollama(model=\"qwen2.5:3b\", temperature=0.5, num_predict=512) "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üéØ Self-Querying Retriever\n",
        "\n",
        "### What is Self-Querying Retriever?\n",
        "\n",
        "The Self-Querying Retriever has the ability to query itself. Given a natural language query, it uses a query-constructing LLM chain to generate a structured query and applies metadata filters.\n",
        "\n",
        "**How it works:**\n",
        "1. Takes a natural language query\n",
        "2. Uses LLM to extract query text and metadata filters\n",
        "3. Applies both semantic search and metadata filtering\n",
        "4. Returns filtered results\n",
        "\n",
        "**Pros:**\n",
        "- Combines semantic search with metadata filtering\n",
        "- Handles complex queries with multiple criteria\n",
        "- More precise results through filtering\n",
        "\n",
        "**Cons:**\n",
        "- Requires well-structured metadata\n",
        "- More complex setup\n",
        "- May miss results if metadata is incomplete"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üìä Dataset for Self-Query Retriever: HuggingFace Daily Papers\n",
        "\n",
        "### Why This Dataset?\n",
        "- **Rich structured metadata**: Papers have natural categorical and temporal attributes (subjects, publication dates)\n",
        "- **Filtering requirements**: Research paper searches often need specific criteria (\"LLM papers from October 2025\")\n",
        "- **Demonstrates Self-Query strength**: Shows how the retriever combines semantic search with metadata filtering\n",
        "- **Real-world use case**: Mirrors actual research paper discovery workflows\n",
        "\n",
        "### Data Creation Pipeline\n",
        "\n",
        "**Step 1: Fetch Raw Data**\n",
        "- Source: HuggingFace Daily Papers API (`https://huggingface.co/api/daily_papers`)\n",
        "- Method: Paginated API calls (10 pages √ó 50 papers = 500 papers)\n",
        "- Fields: title, summary, authors, publishedAt, ai_keywords\n",
        "\n",
        "**Step 2: Transform and Enrich with LLM**\n",
        "- Used Gemma 3:1b model to generate enhanced metadata:\n",
        "  - `three_sentence_summary`: Concise summary of the abstract\n",
        "  - `innovations`: Top 3 key innovations in bullet points\n",
        "  - `subjects`: AI topic classification (LLM, RAG, Agentic AI, etc.)\n",
        "- Date conversion: ISO format ‚Üí Unix timestamp for filtering\n",
        "\n",
        "**Step 3: Create Vector Store Documents**\n",
        "- **page_content**: LLM-generated three-sentence summary (semantic search target)\n",
        "- **metadata**: \n",
        "  - `title` (string): Paper title\n",
        "  - `subject` (string): Primary subject classification\n",
        "  - `date` (integer): Unix timestamp for date-range queries\n",
        "\n",
        "**Result**: 500 semantically-searchable papers with filterable metadata stored in Chroma (`sq_hf` directory)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "import json\n",
        "\n",
        "with open(config.TRANSFORMED_PAPERS_PATH, 'r') as file:\n",
        "   transformed_papers = json.load(file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from datetime import datetime\n",
        "\n",
        "sq_documents = []\n",
        "for paper in transformed_papers:\n",
        "    # Convert date string to timestamp\n",
        "    date_obj = datetime.strptime(paper['date'], '%Y-%m-%d')\n",
        "    timestamp = int(date_obj.timestamp())\n",
        "    \n",
        "    document = Document(\n",
        "        page_content=paper[\"three_sentence_summary\"],\n",
        "        metadata={\n",
        "            \"title\": paper['title'],\n",
        "            \"subject\": paper['subjects'].split(',')[0],\n",
        "            \"date\": timestamp,  \n",
        "        }\n",
        "    )\n",
        "    sq_documents.append(document)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Creating vector store for multi-query retriever\n",
            " Vector store created!\n"
          ]
        }
      ],
      "source": [
        "# Create vector store\n",
        "print(\" Creating vector store for multi-query retriever\")\n",
        "vectorstore = Chroma.from_documents(\n",
        "    documents=sq_documents,\n",
        "    embedding=embeddings,\n",
        "    persist_directory=os.path.join(config.CHROMA_PERSIST_DIRECTORY, \"sq_hf\")\n",
        ")\n",
        "print(\" Vector store created!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define metadata field information for Self-Querying Retriever\n",
        "metadata_field_info = [\n",
        "    AttributeInfo(\n",
        "        name=\"title\",\n",
        "        description=\"The title of the paper related to AI from Huggingface Daily Papers\",\n",
        "        type=\"string\",\n",
        "    ),\n",
        "\n",
        "    AttributeInfo(\n",
        "        name=\"subjects\",\n",
        "        description=\"The subject of the paper. Options:LLM, SLM, VLM, Agentic RAG, AI agents, Agentic AI, RAG, multi-agent, RLHF, prompt engineering, context engineering, Agent, RLHF, Reinforcement learning, prompt, GPT and other related topics\",\n",
        "        type=\"string\",\n",
        "    ),\n",
        "    AttributeInfo(\n",
        "        name=\"date\",\n",
        "        description=\"The publication date as Unix timestamp (integer). Use this for date comparisons.\",\n",
        "        type=\"integer\",\n",
        "    ),\n",
        "]\n",
        "\n",
        "document_content_description = \"Research papers from huggingface daily papers.\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üéØ Setting up Self-Querying Retriever...\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Self-Querying Retriever ready!\n"
          ]
        }
      ],
      "source": [
        "# Create Self-Querying Retriever\n",
        "print(\"üéØ Setting up Self-Querying Retriever...\")\n",
        "self_query_retriever = SelfQueryRetriever.from_llm(\n",
        "    llm_self_query,\n",
        "    vectorstore,\n",
        "    document_content_description,\n",
        "    metadata_field_info,\n",
        "    verbose=True\n",
        ")\n",
        "print(\"‚úÖ Self-Querying Retriever ready!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "query=\"papers on Generative Models?\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üéØ Testing Self-Querying Retriever...\n",
            "Query: 'papers on Genrative Models?'\n",
            "Results: 4 documents\n"
          ]
        }
      ],
      "source": [
        "print(\"üéØ Testing Self-Querying Retriever...\")\n",
        "\n",
        "\n",
        "\n",
        "self_query_results1 = self_query_retriever.invoke(query)\n",
        "print(f\"Query: '{query}'\")\n",
        "print(f\"Results: {len(self_query_results1)} documents\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Title:  From Data to Rewards: a Bilevel Optimization Perspective on Maximum\n",
            "  Likelihood Estimation\n",
            "Subject:  Generative models\n",
            "Date:  1759874400\n",
            "Page content:  This research explores a novel optimization framework for generative models to improve generalization and robustness. Utilizing Bilevel Optimization, the work addresses the challenge of reward signal scarcity by incorporating a policy gradient objective within an outer-level optimization problem.  The theoretical analysis and code release demonstrate the framework‚Äôs applicability to tabular classification and model-based reinforcement learning, offering a potential solution to alignment challenges in generative AI.\n",
            "\n",
            " ---------------------------------------------------------\n",
            "Title:  GRACE: Generative Representation Learning via Contrastive Policy\n",
            "  Optimization\n",
            "Subject:  Large Language Models\n",
            "Date:  1759701600\n",
            "Page content:  GRACE is a new framework that trains LLMs to generate explicit rationales alongside embeddings, transforming them into interpretable agents. By optimizing for similarity between query and negative examples, GRACE significantly improves the model‚Äôs performance on benchmarks and retains general capabilities.  The results demonstrate a powerful approach to combining representation learning with generative reasoning, offering transparent and verifiable model behavior.\n",
            "\n",
            " ---------------------------------------------------------\n",
            "Title:  InstructX: Towards Unified Visual Editing with MLLM Guidance\n",
            "Subject:  LLM\n",
            "Date:  1759960800\n",
            "Page content:  InstructX is a new framework that integrates Multimodal Large Language Models (MLLMs) with diffusion models for improved image and video editing. This approach allows for emergent video editing capabilities through training on image data alone, effectively unifying these tasks within a single model. Extensive experimentation demonstrates the effectiveness of InstructX in handling diverse editing challenges and achieving state-of-the-art results.\n",
            "\n",
            " ---------------------------------------------------------\n",
            "Title:  Continuously Augmented Discrete Diffusion model for Categorical\n",
            "  Generative Modeling\n",
            "Subject:  Agentic AI\n",
            "Date:  1759269600\n",
            "Page content:  CADD introduces a continuous latent space augmentation for discrete diffusion models, replacing the ‚Äòinformation void‚Äô with graded latent vectors that guide denoising. This framework enhances generative quality through a controllable trade-off between mode-coverage and mode-seeking, achieving superior results across diverse tasks.  The design is compatible with existing discrete diffusion training, offering improved generative outcomes compared to traditional methods.\n",
            "\n",
            " ---------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "for result in self_query_results1:\n",
        "    print(\"Title: \", result.metadata['title'])\n",
        "    print(\"Subject: \", result.metadata['subject'])\n",
        "    print(\"Date: \", result.metadata['date'])\n",
        "    print(\"Page content: \", result.page_content)\n",
        "    print(\"\\n ---------------------------------------------------------\")\n",
        "    "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "######################################################################################## ########################################################################################"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üîç Multi-Query Retriever\n",
        "\n",
        "### What is Multi-Query Retriever?\n",
        "\n",
        "The Multi-Query Retriever addresses the limitation that retrieval results may vary with subtle changes in query wording. It uses an LLM to generate multiple queries from different perspectives for a given user input query.\n",
        "\n",
        "**How it works:**\n",
        "1. Takes a user query\n",
        "2. Uses LLM to generate multiple query variations\n",
        "3. Retrieves documents for each query variation\n",
        "4. Returns the union of all results\n",
        "\n",
        "**Pros:**\n",
        "- Captures different perspectives on the same question\n",
        "- Reduces sensitivity to query wording\n",
        "- Provides more comprehensive results\n",
        "\n",
        "**Cons:**\n",
        "- More computationally expensive\n",
        "- May return redundant results\n",
        "- Requires LLM for query generation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üìö Dataset for Multi-Query Retriever: Course FAQ Data\n",
        "\n",
        "### Why This Dataset?\n",
        "- **Natural query variation**: Course questions can be asked in many different ways\n",
        "- **Simple metadata structure**: Focus is on semantic similarity, not complex filtering\n",
        "- **Demonstrates Multi-Query strength**: Shows how query expansion captures different phrasings\n",
        "- **Common use case**: FAQ retrieval benefits from understanding multiple question formulations\n",
        "\n",
        "### Data Source and Structure\n",
        "\n",
        "**Source**: DataTalks Club LLM Zoomcamp FAQ\n",
        "- URL: `https://raw.githubusercontent.com/DataTalksClub/llm-zoomcamp/main/03-evaluation/search_evaluation/documents-with-ids.json`\n",
        "- Pre-structured JSON with validated Q&A pairs\n",
        "- Multiple courses and modules included\n",
        "\n",
        "**Data Creation Process**:\n",
        "- **Direct loading**: No transformation needed - data already in FAQ format\n",
        "- **Document structure**:\n",
        "  - **page_content**: The FAQ question (what users search for)\n",
        "  - **metadata**:\n",
        "    - `answer`: Full answer text\n",
        "    - `section`: Course module (e.g., \"Module 1: Docker and Terraform\")\n",
        "    - `course`: Course identifier (e.g., \"data-engineering-zoomcamp\")\n",
        "    - `id`: Unique identifier\n",
        "\n",
        "**Why Questions as page_content?**\n",
        "- Users search with questions, so embedding questions enables better semantic matching\n",
        "- Answers stored in metadata for retrieval after matching\n",
        "- Query expansion helps match different ways of asking the same question\n",
        "\n",
        "**Result**: Comprehensive FAQ knowledge base stored in Chroma (`mq_faq` directory) optimized for multi-perspective retrieval"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "import requests \n",
        "\n",
        "docs_url = 'https://raw.githubusercontent.com/DataTalksClub/llm-zoomcamp/refs/heads/main/03-evaluation/search_evaluation/documents-with-ids.json'\n",
        "\n",
        "documents = requests.get(docs_url).json()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'text': 'For those who wish to use the backslash as an escape character in Git Bash for Windows (as Alexey normally does), type in the terminal: bash.escapeChar=\\\\ (no need to include in .bashrc)',\n",
              " 'section': 'Module 1: Docker and Terraform',\n",
              " 'question': 'Git Bash - Backslash as an escape character in Git Bash for Windows',\n",
              " 'course': 'data-engineering-zoomcamp',\n",
              " 'id': '2f83dbe7'}"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "documents[50]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Create LangChain Documents\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "faq_documents=[]\n",
        "for doc in documents:\n",
        "    document=Document(\n",
        "        page_content=doc[\"question\"],\n",
        "        metadata={\n",
        "            \"answer\": doc['text'],\n",
        "            \"section\": doc['section'],\n",
        "            \"course\": doc['course'],\n",
        "            \"id\": doc['id']\n",
        "        }\n",
        "    )\n",
        "    faq_documents.append(document)\n",
        "\n",
        "    "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Build Vector Store - Multi-Query Retreival\n",
        "\n",
        "Create a Chroma vector database from our documents using the embedding model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Creating vector store for multi-query retriever\n",
            " Vector store created!\n"
          ]
        }
      ],
      "source": [
        "# Create vector store\n",
        "print(\" Creating vector store for multi-query retriever\")\n",
        "vectorstore = Chroma.from_documents(\n",
        "    documents=faq_documents,\n",
        "    embedding=embeddings,\n",
        "    persist_directory=os.path.join(config.CHROMA_PERSIST_DIRECTORY, \"mq_faq\")\n",
        ")\n",
        "print(\" Vector store created!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Custom Prompt Template\n",
        "\n",
        "1. Import  the PromptTemplate class to create a custom prompt for query generation.\n",
        "2. Create a specialized prompt that instructs the LLM to generate 3 alternative versions of the user's query."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "from langchain_core.prompts.prompt import PromptTemplate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [],
      "source": [
        "prompt=PromptTemplate(\n",
        "    input_variables=[\"question\"],\n",
        "    template=\"\"\"You are an AI language model assistant. Your task is\n",
        "    to generate 3 different versions of the given user\n",
        "    query to retrieve relevant documents from a vector database.\n",
        "    The database consists of FAQ questions and answers from a course.\n",
        "    The query is supposed to be a general questions about the course.\n",
        "    Your task is to generate 3 different versions of the query.\n",
        "    your goal is to help the user overcome some of the limitations of distance-based similarity search. Provide these alternative\n",
        "    queries separated by newlines. Original query: {question}\"\"\",\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Raw LLM output (generated queries):\n",
            "Okay, here are 3 different versions of the query, designed to help retrieve relevant documents from the vector database, focusing on broader understanding and addressing potential limitations of a distance-based search:\n",
            "\n",
            "**Version 1:**  ‚ÄúWhat is the official start date for the [Course Name] course?‚Äù\n",
            "\n",
            "**Version 2:** ‚ÄúCan you provide a timeline for the [Course Name] course, including the enrollment date and initial class start?‚Äù\n",
            "\n",
            "**Version 3:** ‚ÄúWhat are the key dates associated with the [Course Name] course, such as the first session, and what‚Äôs the general timeframe for the course?‚Äù \n",
            "\n",
            "---\n",
            "\n",
            "Let me know if you‚Äôd like me to generate more variations or want me to focus on a specific aspect of the query (e.g., focusing on specific topics within the course).\n"
          ]
        }
      ],
      "source": [
        "test_query = \"when does the course start?\"\n",
        "formatted_prompt = prompt.format(question=test_query)\n",
        "generated_text = llm_multi_query.invoke(formatted_prompt)\n",
        "\n",
        "print(\"Raw LLM output (generated queries):\")\n",
        "print(generated_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üîç Setting up Multi-Query Retriever...\n",
            "‚úÖ Multi-Query Retriever ready!\n"
          ]
        }
      ],
      "source": [
        "# Create Multi-Query Retriever\n",
        "print(\"üîç Setting up Multi-Query Retriever...\")\n",
        "multi_query_retriever = MultiQueryRetriever.from_llm(\n",
        "    retriever=vectorstore.as_retriever(search_kwargs={\"k\": 1}),\n",
        "    prompt=prompt,\n",
        "    llm=llm\n",
        ")\n",
        "print(\"‚úÖ Multi-Query Retriever ready!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'General course-related questions'"
            ]
          },
          "execution_count": 58,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "documents[0]['section']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üîç Testing Multi-Query Retriever...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:langchain.retrievers.multi_query:Generated queries: ['Okay, here are 3 different versions of the query, designed to help retrieve relevant documents from a vector database, focusing on a general understanding of the course‚Äôs start date and addressing potential limitations of a purely distance-based search:', '**Version 1:**  ‚ÄúWhat is the official start date for the Data Engineering course?‚Äù', '**Version 2:** ‚ÄúCan you provide the enrollment date for the Data Engineering course?‚Äù', '**Version 3:** ‚ÄúWhat‚Äôs the timeline for the Data Engineering course, including the beginning date?‚Äù']\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üìã Multi-Query Results (3 documents):\n",
            "\n",
            "--- Result 1 ---\n",
            "Content: \n",
            " Course - When will the course start?\n",
            "Metadata: \n",
            " General course-related questions\n",
            "\n",
            "--- Result 2 ---\n",
            "Content: \n",
            " Course - I have registered for the Data Engineering Bootcamp. When can I expect to receive the confirmation email?\n",
            "Metadata: \n",
            " General course-related questions\n",
            "\n",
            "--- Result 3 ---\n",
            "Content: \n",
            " What are the deadlines in this course?\n",
            "Metadata: \n",
            " General course-related questions\n"
          ]
        }
      ],
      "source": [
        "# Test Multi-Query Retriever\n",
        "print(\"üîç Testing Multi-Query Retriever...\")\n",
        "test_query = \"when does the data engineering course start?\"\n",
        "multi_query_results = multi_query_retriever.invoke(test_query)\n",
        "\n",
        "print(f\"üìã Multi-Query Results ({len(multi_query_results)} documents):\")\n",
        "for i, doc in enumerate(multi_query_results):\n",
        "    print(f\"\\n--- Result {i+1} ---\")\n",
        "    print(f\"Content: \\n {doc.page_content}\")\n",
        "    print(f\"Metadata: \\n {doc.metadata['section']}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üìã Comparison Summary\n",
        "\n",
        "| Aspect | Multi-Query Retriever | Self-Querying Retriever |\n",
        "|--------|----------------------|------------------------|\n",
        "| **Primary Use Case** | Query variation and comprehensive results | Metadata filtering with semantic search |\n",
        "| **Query Processing** | Generates multiple query variations | Extracts query text + metadata filters |\n",
        "| **Result Quality** | Broader, more comprehensive | More precise, filtered results |\n",
        "| **Metadata Usage** | Limited | Extensive |\n",
        "| **Best For** | Exploratory search, research | Filtered search, specific criteria |\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üéØ When to Use Each Retriever\n",
        "\n",
        "### Use Multi-Query Retriever when:\n",
        "- ‚úÖ You want comprehensive results from different perspectives\n",
        "- ‚úÖ Query wording might vary significantly\n",
        "- ‚úÖ You're doing exploratory research\n",
        "- ‚úÖ You need to capture different ways of asking the same question\n",
        "- ‚úÖ You have limited metadata or don't need filtering\n",
        "\n",
        "### Use Self-Querying Retriever when:\n",
        "- ‚úÖ You have rich, structured metadata\n",
        "- ‚úÖ You need precise filtering capabilities\n",
        "- ‚úÖ You want to combine semantic search with metadata filters\n",
        "- ‚úÖ You have specific criteria (date ranges, categories, etc.)\n",
        "- ‚úÖ You need faster, more targeted results\n",
        "\n",
        "### Use Both Together when:\n",
        "- ‚úÖ You need both comprehensive coverage AND precise filtering\n",
        "- ‚úÖ You're building a complex search system\n",
        "- ‚úÖ You want to combine the benefits of both approaches\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üéì Key Takeaways\n",
        "\n",
        "### Multi-Query Retriever:\n",
        "- **Best for**: Exploratory research, comprehensive coverage\n",
        "- **Strengths**: Captures different perspectives, reduces query sensitivity\n",
        "- **Trade-offs**: Higher computational cost, potential redundancy\n",
        "\n",
        "### Self-Querying Retriever:\n",
        "- **Best for**: Precise filtering, structured data\n",
        "- **Strengths**: Combines semantic search with metadata filtering\n",
        "- **Trade-offs**: Requires rich metadata, more complex setup\n",
        "\n",
        "### Hybrid Approach:\n",
        "- **Best for**: Complex applications needing both coverage and precision\n",
        "- **Strengths**: Combines benefits of both approaches\n",
        "- **Trade-offs**: Highest computational cost, most complex setup\n",
        "\n",
        "## üèÅ Conclusion\n",
        "\n",
        "Both retrievers serve different purposes in the retrieval ecosystem:\n",
        "- Use **Multi-Query** when you need comprehensive, diverse results\n",
        "- Use **Self-Querying** when you need precise, filtered results  \n",
        "- Use **Hybrid** when you need the best of both worlds\n",
        "\n",
        "The choice depends on your specific use case, data structure, and performance requirements.\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "retrievers",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
